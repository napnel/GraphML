{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUTAG(188)\n",
      "188 7 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root=Path().cwd().parent / \"datasets\", name=\"MUTAG\")\n",
    "\n",
    "print(dataset)\n",
    "print(len(dataset), dataset.num_features, dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n",
      "17 38\n",
      "False False True\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import degree\n",
    "graph = dataset[0]\n",
    "print(graph)\n",
    "print(graph.num_nodes, graph.num_edges)\n",
    "print(graph.has_isolated_nodes(), graph.has_self_loops(), graph.is_undirected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "dataset = dataset.shuffle()\n",
    "dataset_train = dataset[:150]\n",
    "dataset_test = dataset[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 1238], x=[570, 7], edge_attr=[1238, 4], y=[32], batch=[570], ptr=[33]) \n",
      "\n",
      "torch.Size([570])\n",
      "Step: 1, Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 1286], x=[580, 7], edge_attr=[1286, 4], y=[32], batch=[580], ptr=[33]) \n",
      "\n",
      "torch.Size([580])\n",
      "Step: 2, Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 1274], x=[574, 7], edge_attr=[1274, 4], y=[32], batch=[574], ptr=[33]) \n",
      "\n",
      "torch.Size([574])\n",
      "Step: 3, Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 1276], x=[575, 7], edge_attr=[1276, 4], y=[32], batch=[575], ptr=[33]) \n",
      "\n",
      "torch.Size([575])\n",
      "Step: 4, Number of graphs in the current batch: 22\n",
      "DataBatch(edge_index=[2, 848], x=[383, 7], edge_attr=[848, 4], y=[22], batch=[383], ptr=[23]) \n",
      "\n",
      "torch.Size([383])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "loader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(loader_train):\n",
    "    print(f\"Step: {step}, Number of graphs in the current batch: {data.num_graphs}\")\n",
    "    print(data, \"\\n\")\n",
    "    print(data.batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GINConv\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_hiddens, num_classes):\n",
    "        super(GIN, self).__init__()\n",
    "        torch.manual_seed(0)\n",
    "        self.conv1 = GINConv(Linear(num_features, num_hiddens))\n",
    "        self.conv2 = GINConv(Linear(num_hiddens, num_hiddens))\n",
    "        self.conv3 = GINConv(Linear(num_hiddens, num_hiddens))\n",
    "        self.lin = Linear(num_hiddens, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        \n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 1182], x=[539, 7], edge_attr=[1182, 4], y=[32], batch=[539], ptr=[33])\n",
      "torch.Size([539, 7]) tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 1])\n",
      "torch.Size([32, 7])\n"
     ]
    }
   ],
   "source": [
    "graph_batch = iter(loader_train).__next__()\n",
    "print(graph_batch)\n",
    "print(graph_batch.x.shape, graph_batch.y)\n",
    "emb = global_mean_pool(graph_batch.x, graph_batch.batch)\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph_batchには32個のグラフが纏まっており、各グラフに対して０か１が割り当てられている。\n",
    "今回の場合32個のグラフは539個の頂点を持っている。\n",
    "global_mean_poolは１つのグラフに平均化している。\n",
    "![](../images/mini-batching-of-graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (conv1): GINConv(nn=Linear(in_features=7, out_features=64, bias=True))\n",
      "  (conv2): GINConv(nn=Linear(in_features=64, out_features=64, bias=True))\n",
      "  (conv3): GINConv(nn=Linear(in_features=64, out_features=64, bias=True))\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "Epoch: 010, Train Acc: 0.667, Test Acc: 0.684\n",
      "Epoch: 020, Train Acc: 0.740, Test Acc: 0.816\n",
      "Epoch: 030, Train Acc: 0.733, Test Acc: 0.816\n",
      "Epoch: 040, Train Acc: 0.767, Test Acc: 0.842\n",
      "Epoch: 050, Train Acc: 0.760, Test Acc: 0.816\n",
      "Epoch: 060, Train Acc: 0.767, Test Acc: 0.842\n",
      "Epoch: 070, Train Acc: 0.787, Test Acc: 0.842\n",
      "Epoch: 080, Train Acc: 0.780, Test Acc: 0.842\n",
      "Epoch: 090, Train Acc: 0.787, Test Acc: 0.842\n",
      "Epoch: 100, Train Acc: 0.807, Test Acc: 0.868\n",
      "Epoch: 110, Train Acc: 0.807, Test Acc: 0.842\n",
      "Epoch: 120, Train Acc: 0.787, Test Acc: 0.842\n",
      "Epoch: 130, Train Acc: 0.860, Test Acc: 0.868\n",
      "Epoch: 140, Train Acc: 0.820, Test Acc: 0.868\n",
      "Epoch: 150, Train Acc: 0.867, Test Acc: 0.868\n",
      "Epoch: 160, Train Acc: 0.820, Test Acc: 0.868\n",
      "Epoch: 170, Train Acc: 0.800, Test Acc: 0.789\n",
      "Epoch: 180, Train Acc: 0.813, Test Acc: 0.895\n",
      "Epoch: 190, Train Acc: 0.820, Test Acc: 0.921\n",
      "Epoch: 200, Train Acc: 0.880, Test Acc: 0.842\n"
     ]
    }
   ],
   "source": [
    "model = GIN(dataset.num_features, 64, dataset.num_classes)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(loader: DataLoader, model: torch.nn.Module):\n",
    "    model.train()\n",
    "\n",
    "    for graph in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(graph.x, graph.edge_index, graph.batch)\n",
    "        loss = criterion(out, graph.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(loader: DataLoader, model: torch.nn.Module):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for graph in loader:\n",
    "        out  = model(graph.x, graph.edge_index, graph.batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == graph.y).sum())\n",
    "    \n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train(loader_train, model)\n",
    "    if epoch % 10 == 0:\n",
    "        acc_train = test(loader_train, model)\n",
    "        acc_test = test(loader_test, model)\n",
    "        print(f\"Epoch: {epoch:03d}, Train Acc: {acc_train:.3f}, Test Acc: {acc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_hiddens, num_classes):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(0)\n",
    "        self.conv1 = GraphConv(num_features, num_hiddens)\n",
    "        self.conv2 = GraphConv(num_hiddens, num_hiddens)\n",
    "        self.conv3 = GraphConv(num_hiddens, num_hiddens)\n",
    "        self.lin = Linear(num_hiddens, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GraphConv(7, 64)\n",
      "  (conv2): GraphConv(64, 64)\n",
      "  (conv3): GraphConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "Epoch: 010, Train Acc: 0.700, Test Acc: 0.789\n",
      "Epoch: 020, Train Acc: 0.760, Test Acc: 0.842\n",
      "Epoch: 030, Train Acc: 0.787, Test Acc: 0.868\n",
      "Epoch: 040, Train Acc: 0.800, Test Acc: 0.842\n",
      "Epoch: 050, Train Acc: 0.807, Test Acc: 0.921\n",
      "Epoch: 060, Train Acc: 0.840, Test Acc: 0.921\n",
      "Epoch: 070, Train Acc: 0.873, Test Acc: 0.921\n",
      "Epoch: 080, Train Acc: 0.907, Test Acc: 0.921\n",
      "Epoch: 090, Train Acc: 0.893, Test Acc: 0.895\n",
      "Epoch: 100, Train Acc: 0.900, Test Acc: 0.895\n",
      "Epoch: 110, Train Acc: 0.893, Test Acc: 0.947\n",
      "Epoch: 120, Train Acc: 0.860, Test Acc: 0.947\n",
      "Epoch: 130, Train Acc: 0.880, Test Acc: 0.895\n",
      "Epoch: 140, Train Acc: 0.913, Test Acc: 0.921\n",
      "Epoch: 150, Train Acc: 0.913, Test Acc: 0.921\n",
      "Epoch: 160, Train Acc: 0.907, Test Acc: 0.921\n",
      "Epoch: 170, Train Acc: 0.933, Test Acc: 0.921\n",
      "Epoch: 180, Train Acc: 0.920, Test Acc: 0.921\n",
      "Epoch: 190, Train Acc: 0.920, Test Acc: 0.921\n",
      "Epoch: 200, Train Acc: 0.920, Test Acc: 0.921\n"
     ]
    }
   ],
   "source": [
    "model = GNN(dataset.num_features, 64, dataset.num_classes)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train(loader_train, model)\n",
    "    if epoch % 10 == 0:\n",
    "        acc_train = test(loader_train, model)\n",
    "        acc_test = test(loader_test, model)\n",
    "        print(f\"Epoch: {epoch:03d}, Train Acc: {acc_train:.3f}, Test Acc: {acc_test:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c967383f2691357114d2d6d1a678416fb2ed4479689e1d4a2cda79c2e71d2b5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('grl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
